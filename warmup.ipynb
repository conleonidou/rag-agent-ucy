{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warmup Process to Index and Vectorize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Vector Store and Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = 'data/scraped_urls.json'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    raw_data = pickle.load(file)\n",
    "\n",
    "print(raw_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_to_add_to_vectorstore = [item[0] for item in raw_data if item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents_to_add_to_vectorstore[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Documents to Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(documents=documents_to_add_to_vectorstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"Master in Data Science?\", k=5\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Course List with JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def load_course_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        courses = json.load(f)\n",
    "    \n",
    "    documents = []\n",
    "    for i, course in enumerate(courses):\n",
    "        # Convert the course dict to a string representation for the content\n",
    "        content = str(course)\n",
    "        # Use the original dict as metadata\n",
    "        doc = Document(page_content=content, metadata={'source': 'course_list'})\n",
    "        documents.append(doc)\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    course_docs = load_course_data(\"data/course_list.json\")\n",
    "    print(f\"\\nSimple loader: Successfully loaded {len(course_docs)} documents\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with simple loader: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(documents=course_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Retrieval with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"Erasmus\", k=5, filter={\"source\": \"course_list\"}\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firecrawl for UCY Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firecrawl import FirecrawlApp, ScrapeOptions\n",
    "\n",
    "app = FirecrawlApp(api_key=\"\")\n",
    "\n",
    "# Crawl a website:\n",
    "crawl_result = app.crawl_url(\n",
    "  'https://www.ucy.ac.cy/?lang=en', \n",
    "  limit=10,\n",
    "  scrape_options=ScrapeOptions(formats=['markdown']),\n",
    ")\n",
    "print(crawl_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown files splitting and indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 72 markdown files to process.\n",
      "Processing: www.ucy.ac.cy_graduateschool_people_board.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_language-of-instruction-and-duration-of-studies.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_itis_policies.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_aasw_student-welfare_housing-office_summer-accommodation.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: dsi.education.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_aasw_studies_undergraduate-studies_international_students.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_sap_ma-peace-conflict-democracy.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_internationalsupport_home_faq.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_byz.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_postgraduate-programme-places-for-the-fall-semester-of-the-academic-year-2025-2026-entry-september-2025.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_diploma-supplement.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_attendance_regulations.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_aasw_studies_undergraduate-studies_exam-schedule.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_postgraduate-programmes-places.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_scholarships-for-siblings-or-first-degree-relatives-or-married-partners-3.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_aasw_student-welfare_housing-office_activities.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduation.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_internationalsupport_home_forms.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.cs.ucy.ac.cy_index.php_education_postgrad_master-in-artificial-intelligence.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_mhc_meeting-arrangements.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_aasw_student-welfare_housing-office_private-accommodation.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_medical_master_programme_english.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_fees-phd-students.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_services.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_aasw_studies_undergraduate-studies_schedule-classes.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_conservation.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_edu_programmes-of-study_postgraduate_programmes_creative-learning.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_itis_working-hours.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_aasw_student-welfare_social-support_financial-support.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_application_forms.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_expressservices_area-of-responsibility.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_fees.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_apply-now.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_aasw_student-welfare_housing-office_resident-assistants.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_econ_master-in-behavioural-economics.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_admission-requirements-2.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_aasw_student-welfare_housing-office_student-halls.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_cee_programmes-of-study_postgraduate-programmes_meng-in-civil-engineering.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_aasw_student-welfare_housing-office_applying-for-accommodation.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_faq-2.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_assistance-student-offers.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_registration-in-courses-for-the-spring-semester-2024-2025.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_internationalsupport.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_vision.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_useful-information.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_registration-procedure-registration-in-courses-phd.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_econ_time-mbe.md...\n",
      "  -> Processed into 4 chunks.\n",
      "Processing: cs.ucy.ac.cy_index.php_education_postgrad_master-in-cognitive-systems.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_aasw_studies_undergraduate-studies_upopsifioi-apo-ellada.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_publications_studying-at-ucy.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_scholarships.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_afn_programmes-of-study_master-in-finance.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_requirements-for-master.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy.md...\n",
      "  -> Processed into 4 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_procedure-for-a-dissertation-defense-presentation-of-a-ph-d-thesis.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_rules-for-co-supervision-of-ph-d-thesis.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_requirements-for-phd-degree.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_aasw_studies_undergraduate-studies_candidates_from_cyprus.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_aasw_bannerweb.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_aasw_studies_undergraduate-studies_undergraduate_rules.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.globed.eu.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_postgraduate-programme-places-for-the-fall-semester-of-the-academic-year-2025-2026-entry-september-202.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_dhla.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_mhc.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_eng_programmes-of-study_ma-programmes.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_mba.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_health-care-for-students.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_structure-specifications-approve-of-ph-d-thesis.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_cee_programmes-of-study_postgraduate-programmes_msc-in-civil-engineering.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_expressservices_university_card.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_graduateschool_ects-system.md...\n",
      "  -> Processed into 1 chunks.\n",
      "Processing: www.ucy.ac.cy_itis_services.md...\n",
      "  -> Processed into 1 chunks.\n",
      "\n",
      "Total document chunks created: 78\n",
      "Embedding dimension detected: 768\n",
      "\n",
      "Adding 78 processed document chunks to FAISS vector store...\n",
      "Documents added successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration for Markdown processing ---\n",
    "MARKDOWN_FILES_PATH = \"data/markdown_extracts/\"\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "]\n",
    "\n",
    "markdown_files = glob.glob(os.path.join(MARKDOWN_FILES_PATH, \"*.md\"))\n",
    "all_split_documents = []\n",
    "\n",
    "if not markdown_files:\n",
    "    print(f\"No markdown files found in {MARKDOWN_FILES_PATH}\")\n",
    "else:\n",
    "    print(f\"Found {len(markdown_files)} markdown files to process.\")\n",
    "\n",
    "# Initialize the Markdown splitter\n",
    "md_splitter = MarkdownHeaderTextSplitter(headers_to_split_on)\n",
    "\n",
    "for md_file_path in markdown_files:\n",
    "    filename = os.path.basename(md_file_path)\n",
    "    print(f\"Processing: {filename}...\")\n",
    "    try:\n",
    "        with open(md_file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()  # 'content' is a string\n",
    "        \n",
    "        # The error indicates that split_text is returning a list of Document objects.\n",
    "        # Let's call the output 'document_chunks_from_splitter'\n",
    "        document_chunks_from_splitter = md_splitter.split_text(content)\n",
    "        \n",
    "        # Iterate through the Document objects returned by the splitter\n",
    "        for i, doc_chunk in enumerate(document_chunks_from_splitter):\n",
    "            # 'doc_chunk' is already a Document object here.\n",
    "            # We need to add/update its metadata.\n",
    "\n",
    "            # Ensure the metadata attribute exists and is a dictionary\n",
    "            if not hasattr(doc_chunk, 'metadata') or doc_chunk.metadata is None:\n",
    "                doc_chunk.metadata = {}  # Initialize if not present or None\n",
    "            \n",
    "            # Add your custom metadata\n",
    "            doc_chunk.metadata[\"source\"] = filename\n",
    "            doc_chunk.metadata[\"chunk_index\"] = i\n",
    "            \n",
    "            # Append the (now modified) Document object to your list\n",
    "            all_split_documents.append(doc_chunk)\n",
    "            \n",
    "        print(f\"  -> Processed into {len(document_chunks_from_splitter)} chunks.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal document chunks created: {len(all_split_documents)}\")\n",
    "\n",
    "# Check if embeddings are initialized and get dimension\n",
    "if 'embeddings' not in globals() or embeddings is None:\n",
    "    raise ValueError(\"The 'embeddings' object must be initialized before creating the FAISS index.\")\n",
    "try:\n",
    "    # It's safer to embed a short, constant string to get the dimension\n",
    "    test_embedding = embeddings.embed_query(\"dimension_check\")\n",
    "    embedding_dimension = len(test_embedding)\n",
    "    print(f\"Embedding dimension detected: {embedding_dimension}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Could not determine embedding dimension using embeddings.embed_query: {e}\")\n",
    "\n",
    "\n",
    "index = faiss.IndexFlatL2(embedding_dimension) # Use the dynamically determined dimension\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings, # This should be your initialized embedding model\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "# --- Add the processed documents to the vector store ---\n",
    "if all_split_documents:\n",
    "    print(f\"\\nAdding {len(all_split_documents)} processed document chunks to FAISS vector store...\")\n",
    "    vector_store.add_documents(all_split_documents)\n",
    "    print(\"Documents added successfully.\")\n",
    "else:\n",
    "    print(\"\\nNo documents were processed to add to the vector store.\")\n",
    "\n",
    "# --- Save the vector store ---\n",
    "# FAISS_INDEX_SAVE_PATH = \"faiss_index_markdown\" # Consider a new name to avoid overwriting old index if needed\n",
    "# print(f\"\\nSaving FAISS index to: {FAISS_INDEX_SAVE_PATH}\")\n",
    "# vector_store.save_local(FAISS_INDEX_SAVE_PATH)\n",
    "# print(\"FAISS index saved.\")\n",
    "\n",
    "# To use this new index in your tools.py, you'd change:\n",
    "# FAISS.load_local(\"faiss_index\", ...) to FAISS.load_local(\"faiss_index_markdown\", ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving FAISS index to: faiss_index\n",
      "FAISS index saved.\n"
     ]
    }
   ],
   "source": [
    "# --- Save the vector store ---\n",
    "FAISS_INDEX_SAVE_PATH = \"faiss_index\" # Consider a new name to avoid overwriting old index if needed\n",
    "print(f\"\\nSaving FAISS index to: {FAISS_INDEX_SAVE_PATH}\")\n",
    "vector_store.save_local(FAISS_INDEX_SAVE_PATH)\n",
    "print(\"FAISS index saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
